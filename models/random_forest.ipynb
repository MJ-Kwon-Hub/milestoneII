{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/urgedata/pythondata/blob/master/rf_timeseries/Random%20Forest%20for%20Time%20Series%20Forecasting.ipynb\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.ensemble._forest import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import math\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime, date\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize']=(20,10)\n",
        "plt.style.use('ggplot') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set variables\n",
        "\n",
        "df_feature=pd.read_csv('../data/df_feature.csv')\n",
        "X=pd.read_csv('../data/X_data_tr.csv', index_col='date', parse_dates=True)\n",
        "y=pd.read_csv('../data/y_data_tr.csv', index_col='date', parse_dates=True)\n",
        "\n",
        "selected_features=list(df_feature[df_feature.select==1]['variable'])\n",
        "X_train=np.array(X[selected_features][:-96])\n",
        "y_train=np.array(y['y_oecd'][:-96])\n",
        "X_test=np.array(X[selected_features][-96:])\n",
        "y_test=np.array(y['y_oecd'][-96:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.82      0.81        68\n",
            "         1.0       0.52      0.46      0.49        28\n",
            "\n",
            "    accuracy                           0.72        96\n",
            "   macro avg       0.65      0.64      0.65        96\n",
            "weighted avg       0.71      0.72      0.71        96\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "RF_Model = RandomForestClassifier(n_estimators=100,n_jobs=-1,\n",
        "                                 max_features=1, oob_score=True)\n",
        "labels = y_train  #[:, None]\n",
        "features = X_train  ##[:, None]\n",
        "rgr=RF_Model.fit(features, labels)\n",
        "\n",
        "X_test_predict=pd.DataFrame(\n",
        "    rgr.predict(X_test)).rename(  ##[:, None]\n",
        "    columns={0:'predicted'})  ##.set_index('predicted')\n",
        "\n",
        "X_train_predict=pd.DataFrame(\n",
        "    rgr.predict(X_train)).rename(\n",
        "    columns={0:'predicted'})   ##.set_index('predicted')\n",
        "\n",
        "\n",
        "X_test_predict['real']=y_test\n",
        "\n",
        "\n",
        "print(classification_report(X_test_predict['real'], X_test_predict['predicted']))\n",
        "\n",
        "#RF_predict = X_train_predict.append(X_test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "y_true and y_pred have different number of output (1!=2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# evaluation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r2_score(y_train[:, \u001b[39mNone\u001b[39;49;00m], X_train_predict\u001b[39m.\u001b[39;49mreset_index()\u001b[39m.\u001b[39;49mvalues)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/milestoneII-GYt9I6pr/lib/python3.10/site-packages/sklearn/metrics/_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[1;32m    785\u001b[0m     y_true,\n\u001b[1;32m    786\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    791\u001b[0m ):\n\u001b[1;32m    792\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \n\u001b[1;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/milestoneII-GYt9I6pr/lib/python3.10/site-packages/sklearn/metrics/_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true and y_pred have different number of output (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m!=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    113\u001b[0m             y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    114\u001b[0m         )\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    117\u001b[0m n_outputs \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    118\u001b[0m allowed_multioutput_str \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mraw_values\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvariance_weighted\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=2)"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "r2_score(y_train[:, None], X_train_predict.reset_index().values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
