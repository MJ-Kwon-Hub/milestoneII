{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import tree\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_tss(data, varname, n_split, test_size=None, gap=0):\n",
    "\n",
    "    tss=TimeSeriesSplit(test_size=test_size, n_splits=n_split, gap=gap)\n",
    "\n",
    "    fig, axs = plt.subplots(n_split, 1, figsize = (15,15), sharex = True) #Number of plots according to n_splits\n",
    "    split = 0\n",
    "\n",
    "    for train_index, test_index in tss.split(data):\n",
    "        train_df = xy_data.iloc[train_index]\n",
    "        test_df = xy_data.iloc[test_index]\n",
    "        \n",
    "        train_df[varname].plot(ax=axs[split],\n",
    "                        label = 'Training Set',\n",
    "                        title = f'Data Train/Test Split {split}')\n",
    "        test_df[varname].plot(ax=axs[split],\n",
    "                        label = 'Testing Set')\n",
    "        axs[split].axvline(test_index.min(), color = 'black', ls='--')\n",
    "\n",
    "        \n",
    "        split +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through all possible feature types by code\n",
    "\n",
    "def select_features(metadata, X, threshold, criteria='cum'):  ## criteria can be 'cum' or None (non-cumulative)\n",
    "\n",
    "    n=len(metadata['group'].unique())-1\n",
    "\n",
    "    for code in range(n):\n",
    "        # # separating a group of features which have the same code\n",
    "        group = metadata[metadata['group']==code+1]\n",
    "        # # getting the names of these features from the metadata df\n",
    "        group_feature_names = list(group['id'])\n",
    "        # # creating a subset of the full_data df having only features with the same code\n",
    "\n",
    "\n",
    "        selected_cols=[colname for colname in group_feature_names if colname in X.columns]\n",
    "\n",
    "    #    print(selected_cols)\n",
    "\n",
    "        data = X[selected_cols]\n",
    "\n",
    "        # dropping nan rows\n",
    "        # subset = subset.dropna(axis=0)\n",
    "        # Getting rid of categorical features within the group, this will be replaced by encoding\n",
    "        # n_df = subset.select_dtypes(include=numerics)\n",
    "        # Running feature scaling and PCA\n",
    "        sc = StandardScaler()\n",
    "        scaled = sc.fit_transform(data)\n",
    "        # PCA\n",
    "        pca = PCA() # with no number of target PCs defined will not do any reduction\n",
    "        pc = pca.fit_transform(scaled)\n",
    "        n_pcs= pca.components_.shape[0]\n",
    "#        print(pca.components_.shape[1])\n",
    "        # getting the most important features and their names within this feature group\n",
    "        most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "        # get the names\n",
    "        most_important_names = [data.columns[most_important[i]] for i in range(n_pcs)]\n",
    "        # Creating a dictionary to summarize features and importance into a dataframe\n",
    "        \n",
    "        dic = {'PC':['PC{}'.format(i) for i in range(n_pcs)],\n",
    "            'variable':[most_important_names[i] for i in range(n_pcs)],\n",
    "            'var_ratio':[pca.explained_variance_ratio_[i] for i in range(n_pcs)],\n",
    "            'var_ratio_cum':np.cumsum([pca.explained_variance_ratio_[i] for i in range(n_pcs)]),\n",
    "            'group':[code+1]*len(range(n_pcs))\n",
    "        }\n",
    "        \n",
    "        if criteria=='cum':\n",
    "            c_var='var_ratio_cum'\n",
    "            threshold_idx=np.argwhere((dic[c_var]>threshold)*np.ones(n_pcs,dtype=int)==1).min()\n",
    "            dic['select']=[1 if x<=threshold_idx else 0 for x in range(n_pcs)]\n",
    "            \n",
    "        else:\n",
    "            c_var='var_ratio'\n",
    "            threshold_idx=np.where(np.array(dic[c_var])>threshold)\n",
    "            dic['select']=[1 if x in list(threshold_idx[0]) else 0 for x in range(n_pcs)]\n",
    "\n",
    "        if code==0:\n",
    "            df_most_important = pd.DataFrame(dic)\n",
    "        \n",
    "        else:\n",
    "            df=pd.DataFrame(dic)\n",
    "            df_most_important=pd.concat([df_most_important, df], axis=0, ignore_index=True)\n",
    "    \n",
    "    # build the dataframe\n",
    "    df_most_important['title']=df_most_important['variable'].apply(lambda x:metadata[metadata.id==x]['title'].values[0])\n",
    "    \n",
    "\n",
    "    return df_most_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a08393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(df_feature, metadata, k=3):\n",
    "\n",
    "    n=len(metadata['group'].unique())-1\n",
    "\n",
    "    if n%k==0:\n",
    "        n_row=n//k\n",
    "        n_col=k\n",
    "\n",
    "    else:\n",
    "        n_row=n//k+1\n",
    "        n_col=k\n",
    "\n",
    "    fig, ax=plt.subplots(nrows=n_row, ncols=n_col, figsize=(5*n//k, 15))\n",
    "\n",
    "    for code in range(n):\n",
    "\n",
    "        if (code+1)%k==0:\n",
    "            r=(code+1)//k-1\n",
    "            c=n_col-1\n",
    "        else:\n",
    "            r=(code+1)//k\n",
    "            c=(code+1)%k-1\n",
    "\n",
    "\n",
    "        data=df_feature[df_feature.group==code+1]['var_ratio_cum'][:10]\n",
    "        ax[r,c].plot(list(range(len(data))), data)\n",
    "        ax[r,c].set_title('group{}'.format(code+1))\n",
    "        ax[r,c].set_xlabel('number of components')\n",
    "        ax[r,c].set_ylabel('explained var(cum)')\n",
    "        plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
