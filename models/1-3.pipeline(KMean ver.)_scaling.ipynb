{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"881a1869eafe4a2ca0e848363a97448f","deepnote_cell_type":"text-cell-h1"},"source":"# Supervised Learning "},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1e5da1186a5d4836900977d855b69444","deepnote_cell_type":"text-cell-bullet"},"source":"- KNN model, RF model, SVC model Pipeline notebook"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e0fb52d7ce3e474ba3a26e8a68ba697e","deepnote_cell_type":"text-cell-bullet"},"source":"- KNN model pipeline module is knn_result function"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5b4a1679df404503b92c9fd9a8debaa1","deepnote_cell_type":"text-cell-bullet"},"source":"- RF model pipeline module is randomforest_result function"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"76bea83819ff4f45b3d0bba7d1a6683d","deepnote_cell_type":"text-cell-bullet"},"source":"- SVC model pipeline module is svc_result function"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0569bbb0d5b545a7afb5ce1e5ad27be7","deepnote_cell_type":"text-cell-bullet"},"source":"- There are four versions for pipelines: "},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"919c0679fef24d26801ddd5e27e7ce0a","deepnote_cell_type":"text-cell-p"},"source":"1-1. pipeline_scaling : Standard Scaling on X + Using Theoretical group variable"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8a1ef0b3a8404fdcba3bb910657e57e9","deepnote_cell_type":"text-cell-p"},"source":"1-2. pipeline : Using original X + Using Theoretical group variable"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ac24748b6af54cb8b401cb1747c1c904","deepnote_cell_type":"text-cell-p"},"source":"1-3. pipeline(KMean ver.)_scaling:   Standard Scaling on X + Using KMean clustering group variable"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"88a98b64d16a4ff7ac27fdb5e20e057c","deepnote_cell_type":"text-cell-p"},"source":"1-4. pipeline(KMean ver.):   Using original X + Using KMean clustering group variable"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"156f5f2ffcc04b149d252356cd1be4dc","deepnote_cell_type":"text-cell-bullet"},"source":"- Output"},{"cell_type":"markdown","metadata":{"style":"decimal","number":1,"formattedRanges":[],"cell_id":"ad61b644c3464eb6aeffae04239f204e","deepnote_cell_type":"text-cell-number"},"source":"1. Trainded Classifiers are all stored in the folders in result folders named ft_None_{}{}.format(threshold_value for PCA, if X is scaled or not)"},{"cell_type":"markdown","metadata":{"style":"decimal","formattedRanges":[],"cell_id":"b2f5f025c8224328945b0e788f0546f5","deepnote_cell_type":"text-cell-number"},"source":"undefined. CV results for train=validation dataset for all model options are stored in the same folder explained above as df_{}_{}.format(model_type, if it uses KMeans cluster group variable or not)"},{"cell_type":"markdown","metadata":{"style":"decimal","formattedRanges":[],"cell_id":"f563be9a1ca747c6b55e1e6640d5e96c","deepnote_cell_type":"text-cell-number"},"source":"undefined. Classification results for the final test dataset of all model options are are stored in the same folder explained above as df_{}_creport_{}.format(model_type, if it uses KMeans cluster group variable or not)"},{"cell_type":"code","metadata":{"cell_id":"43559542b7f846f99867c6894d7fb63f","deepnote_cell_type":"code"},"source":"# !pip install nbconvert \n# !jupyter nbconvert model_team14.ipynb --to script\n#!pip install numpy -U","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"e7254b66898045f2b9c538d8a37b7494","deepnote_cell_type":"code"},"source":"import model_team14 \nfrom model_team14 import *\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport pickle\n\nfrom sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"57ce8637edd9439c803e51409a6fbf24","deepnote_cell_type":"code"},"source":"############ to use kmean group, select_features-->select_features2 / modelname to add _km  ################# \n\nmetadata=pd.read_csv('../data/full_info.csv')\nthreshold=0.4\ncriteria=None  \n\n#############scaling###############################\npath='../result/ft_{}_{}_scaling'.format(str(criteria), str(threshold))       \n\nif not os.path.exists(path):\n    os.mkdir(path)\n\n## filtering criteria is not cumulative explained variance ratio but just explained variance rati","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"ce22a92738de4c18943e8c54a8225863","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"372ddf4289144665abc43e1145aea6df","deepnote_cell_type":"code"},"source":"def knn_result(metadata, threshold, criteria ,param_knn, y_type='y_agg' ,cv='tss', test_year=5, n_splits=5, dtype='tr'): \n\n    if dtype=='tr':\n        X=pd.read_csv('../data/X_data_tr.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data_tr.csv', index_col='date', parse_dates=True)\n    else:\n        X=pd.read_csv('../data/X_data.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data.csv', index_col='date', parse_dates=True)\n\n################# revise\n    df_feature=select_features2(metadata, X, threshold, criteria=criteria)\n    selected_features=list(df_feature[df_feature.select==1]['variable'])\n    \n    print(selected_features)\n    \n    ## train and validation set: X_train, y_train / final test set: X_test, y_test\n    X_train=X[selected_features][:-(test_year*12)]  \n    y_train=y[y_type][:-(test_year*12)]           \n    X_test=X[selected_features][-(test_year*12):]   \n    y_test=y[y_type][-(test_year*12):]\n    \n    ############################scaling#####################################\n    sc = StandardScaler()\n    X_scaled_train = sc.fit_transform(X_train)\n    X_scaled_test=sc.transform(X_test)\n    \n    data_list=[y_train, y_test]\n    name_list=['y_train', 'y_test']\n\n    for x, name in zip(data_list, name_list):\n        with open(path+'/{}_{}.csv'.format(name,y_type),'wb') as f:\n            pickle.dump(x, f)\n\n    data_list=[X_train, X_test, X_scaled_train, X_scaled_test]\n    name_list=['X_train', 'X_test', 'X_scaled_train', 'X_scaled_test']\n\n    for x, name in zip(data_list, name_list):\n        with open(path+'/{}_km.csv'.format(name),'wb') as f:\n            pickle.dump(x, f)\n    ###############################################################################\n        \n    \n    ## cross validation for parameter tuning & training\n    if cv=='block':\n        split=KFold(n_splits=n_splits, shuffle=False)  \n    else:\n        split=TimeSeriesSplit(n_splits=n_splits)\n        \n    clf = GridSearchCV(KNeighborsClassifier(), param_knn, cv=split,  \n                       verbose=3, n_jobs=-1, scoring=['recall_macro'],\n                    refit='recall_macro'\n                    )\n    ############################scaling####################################\n    clf.fit(X_scaled_train, y_train)\n    \n    ## training result\n    ############################scaling####################################\n    y_pred_prob=clf.predict_proba(X_scaled_test)\n    y_pred = clf.predict(X_scaled_test)\n\n    clf_report=classification_report(y_test, y_pred)\n\n    param=clf.cv_results_['params']\n    mean_test_score=clf.cv_results_['mean_test_recall_macro']\n    std_test_score=clf.cv_results_['std_test_recall_macro']\n    rank_test_score=clf.cv_results_['rank_test_recall_macro']\n\n    for idx, x in enumerate(param):\n        x['model']='KNN'\n        x['data']=dtype\n        x['y']=y_type\n        x['cv']=cv\n        x['mean_test_recall']=mean_test_score[idx] \n        x['std_test_recall']=std_test_score[idx]         \n        x['rank_test_recall']=rank_test_score[idx]\n\n    df_cvresult=pd.DataFrame(param)\n\n    ################# revise\n    with open (path+'/clf_knn_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'wb') as f:  \n        pickle.dump([clf, df_cvresult, y_pred, y_pred_prob, clf_report], f)\n","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"178e168bfee94b0eb9874c5ec5aad4b4","deepnote_cell_type":"code"},"source":"#df_feature=df_feature\nparam_knns=[{'n_neighbors':[1,2,3,5,10],\n            'weights':['uniform','distance']}]  ## you can add more dictionary for other combinations of parameters.\ny_types=['y_agg','y_oecd']\ncvs=['tss']\ntest_year=5\nn_splits=5\ndtypes=['tr','ntr']\n\nfor param_knn in param_knns:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n                knn_result(metadata, threshold, criteria, param_knn, y_type=y_type ,cv=cv, test_year=test_year, n_splits=n_splits, dtype=dtype)","execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"},{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"}]},{"cell_type":"code","metadata":{"cell_id":"813b82d91f76484cac80f63fbccc0272","deepnote_cell_type":"code"},"source":"dict_knn={}\n\nfor param_knn in param_knns:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n################# revise\n                with open (path+'/clf_knn_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'rb') as f:\n                    [clf, df_cvresult, y_pred, y_pred_prob, clf_report]=pickle.load(f)\n################# revise\n                    dict_knn['clf_knn_{}_{}_{}_t{}_spl{}_km'.format(y_type, dtype, cv, test_year, n_splits)]=[clf, df_cvresult, y_pred, y_pred_prob, clf_report]\n                    \nfor idx, model in enumerate(dict_knn):\n    if idx==0:\n        df_knn=dict_knn[model][1]\n    else:\n        df_tmp=dict_knn[model][1]\n        df_knn=pd.concat([df_knn, df_tmp])\n                    \ndf_knn[df_knn.rank_test_recall==1]     \n    ","execution_count":6,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_neighbors</th>\n      <th>weights</th>\n      <th>model</th>\n      <th>data</th>\n      <th>y</th>\n      <th>cv</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>rank_test_recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>5</td>\n      <td>distance</td>\n      <td>KNN</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.595328</td>\n      <td>0.146971</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>distance</td>\n      <td>KNN</td>\n      <td>ntr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.362282</td>\n      <td>0.157250</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>uniform</td>\n      <td>KNN</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.657454</td>\n      <td>0.039490</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>uniform</td>\n      <td>KNN</td>\n      <td>ntr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.536560</td>\n      <td>0.059911</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>distance</td>\n      <td>KNN</td>\n      <td>ntr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.536560</td>\n      <td>0.059911</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   n_neighbors   weights model data       y   cv  mean_test_recall  \\\n7            5  distance   KNN   tr   y_agg  tss          0.595328   \n5            3  distance   KNN  ntr   y_agg  tss          0.362282   \n8           10   uniform   KNN   tr  y_oecd  tss          0.657454   \n4            3   uniform   KNN  ntr  y_oecd  tss          0.536560   \n5            3  distance   KNN  ntr  y_oecd  tss          0.536560   \n\n   std_test_recall  rank_test_recall  \n7         0.146971                 1  \n5         0.157250                 1  \n8         0.039490                 1  \n4         0.059911                 1  \n5         0.059911                 1  "},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"001c89e64ce644ec96f22065a3996d6b","deepnote_cell_type":"code"},"source":"def classification_report_csv(report):\n    report_data = []\n    lines = report.split('\\n')\n    \n    for line in lines[2:len(lines)-5]:\n        row = {}\n        row_data = [val for val in line.split(' ') if val!='']\n        row['class'] = round(float(row_data[0]),0)\n        row['precision'] = float(row_data[1])\n        row['recall'] = float(row_data[2])\n        row['f1_score'] = float(row_data[3])\n        row['support'] = float(row_data[4])\n        row['accuracy']=float([val for val in lines[-4].split(' ') if val!=''][-2])\n        report_data.append(row)\n        \n    df = pd.DataFrame(report_data)\n    return df","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"4fe3fb078bf54a86812648c952c1ce27","deepnote_cell_type":"code"},"source":"for idx, model in enumerate(dict_knn.keys()):\n    \n    report=dict_knn[model][-1]\n    \n    if idx==0:\n        df_knn_creport=classification_report_csv(report)\n        df_knn_creport['model']=model\n    else:\n        df_tmp=classification_report_csv(report)\n        df_tmp['model']=model\n        df_knn_creport=pd.concat([df_knn_creport, df_tmp])\n        \ndf_knn_creport  ##[df_knn_creport_km['class']>0]","execution_count":8,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>support</th>\n      <th>accuracy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.91</td>\n      <td>56.0</td>\n      <td>0.83</td>\n      <td>clf_knn_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.83</td>\n      <td>clf_knn_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.67</td>\n      <td>2.0</td>\n      <td>0.83</td>\n      <td>clf_knn_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>56.0</td>\n      <td>0.93</td>\n      <td>clf_knn_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.93</td>\n      <td>clf_knn_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.93</td>\n      <td>clf_knn_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.96</td>\n      <td>0.89</td>\n      <td>0.93</td>\n      <td>56.0</td>\n      <td>0.87</td>\n      <td>clf_knn_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.33</td>\n      <td>4.0</td>\n      <td>0.87</td>\n      <td>clf_knn_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>56.0</td>\n      <td>0.93</td>\n      <td>clf_knn_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4.0</td>\n      <td>0.93</td>\n      <td>clf_knn_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   class  precision  recall  f1_score  support  accuracy  \\\n0    0.0       0.96    0.86      0.91     56.0      0.83   \n1    1.0       0.00    0.00      0.00      2.0      0.83   \n2    2.0       0.50    1.00      0.67      2.0      0.83   \n0    0.0       0.93    1.00      0.97     56.0      0.93   \n1    1.0       0.00    0.00      0.00      2.0      0.93   \n2    2.0       0.00    0.00      0.00      2.0      0.93   \n0    0.0       0.96    0.89      0.93     56.0      0.87   \n1    1.0       0.25    0.50      0.33      4.0      0.87   \n0    0.0       0.93    1.00      0.97     56.0      0.93   \n1    1.0       0.00    0.00      0.00      4.0      0.93   \n\n                               model  \n0    clf_knn_y_agg_tr_tss_t5_spl5_km  \n1    clf_knn_y_agg_tr_tss_t5_spl5_km  \n2    clf_knn_y_agg_tr_tss_t5_spl5_km  \n0   clf_knn_y_agg_ntr_tss_t5_spl5_km  \n1   clf_knn_y_agg_ntr_tss_t5_spl5_km  \n2   clf_knn_y_agg_ntr_tss_t5_spl5_km  \n0   clf_knn_y_oecd_tr_tss_t5_spl5_km  \n1   clf_knn_y_oecd_tr_tss_t5_spl5_km  \n0  clf_knn_y_oecd_ntr_tss_t5_spl5_km  \n1  clf_knn_y_oecd_ntr_tss_t5_spl5_km  "},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"5c421fa120bd4be8bcb1d638dd3ffb2a","deepnote_cell_type":"code"},"source":"def randomforest_result(metadata, threshold, criteria, param_rf, y_type='y_agg' ,cv='tss', test_year=5, n_splits=5, dtype='tr'):\n    \n    if dtype=='tr':\n        X=pd.read_csv('../data/X_data_tr.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data_tr.csv', index_col='date', parse_dates=True)\n    else:\n        X=pd.read_csv('../data/X_data.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data.csv', index_col='date', parse_dates=True)\n\n################# revise\n    df_feature=select_features2(metadata, X, threshold, criteria=criteria) \n    selected_features=list(df_feature[df_feature.select==1]['variable'])\n    \n    print(selected_features)\n\n    \n    ## train and validation set: X_train, y_train / final test set: X_test, y_test\n    X_train=X[selected_features][:-(test_year*12)]  \n    y_train=y[y_type][:-(test_year*12)]           \n    X_test=X[selected_features][-(test_year*12):]   \n    y_test=y[y_type][-(test_year*12):]\n    \n    ############################scaling#####################################\n    sc = StandardScaler()\n    X_scaled_train = sc.fit_transform(X_train)\n    X_scaled_test=sc.transform(X_test)\n    ############################scaling#####################################\n\n    \n    ## cross validation for parameter tuning & training\n    if cv=='block':\n        split=KFold(n_splits=n_splits, shuffle=False)  \n    else:\n        split=TimeSeriesSplit(n_splits=n_splits)\n        \n    clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=14), \n                       param_rf, cv=split, \n                       verbose=3, n_jobs=-1, scoring=['recall_macro'],\n                    refit='recall_macro'\n                    )\n    \n    ############################scaling#####################################\n    clf.fit(X_scaled_train, y_train)\n    \n    ## training result\n    ############################scaling#####################################\n    y_pred_prob=clf.predict_proba(X_scaled_test)\n    y_pred = clf.predict(X_scaled_test)\n\n    clf_report=classification_report(y_test, y_pred)\n\n    param=clf.cv_results_['params']\n    mean_test_score=clf.cv_results_['mean_test_recall_macro']\n    std_test_score=clf.cv_results_['std_test_recall_macro']\n    rank_test_score=clf.cv_results_['rank_test_recall_macro']\n\n    for idx, x in enumerate(param):\n        x['model']='RF'\n        x['data']=dtype\n        x['y']=y_type\n        x['cv']=cv\n        x['mean_test_recall']=mean_test_score[idx] \n        x['std_test_recall']=std_test_score[idx]         \n        x['rank_test_recall']=rank_test_score[idx]\n\n    df_cvresult=pd.DataFrame(param)\n\n################# revise\n    with open (path+'/clf_rf_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'wb') as f: ################\n        pickle.dump([clf, df_cvresult, y_pred, y_pred_prob, clf_report], f)\n","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"8fefab5eb21d49e2b824f5d7e7bdf223","deepnote_cell_type":"code"},"source":"param_rfs=[{'n_estimators':[30,50,100],\n             'max_features':[0.2, 0.3, 0.5, 0.7, 0.9],\n           'class_weight':['balanced','balanced_subsample',None],\n           'warm_start':[True,False]}]  ## you can add more dictionary for other combinations of parameters.\ny_types=['y_agg','y_oecd']\ncvs=['tss']\ntest_year=5\nn_splits=5\ndtypes=['tr','ntr']\n\nfor param_rf in param_rfs:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n                randomforest_result(metadata, threshold, criteria, param_rf, y_type=y_type ,cv=cv, test_year=test_year, n_splits=n_splits, dtype=dtype)","execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 90 candidates, totalling 450 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:777: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n  warn(\n"},{"name":"stdout","output_type":"stream","text":"['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 90 candidates, totalling 450 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"},{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 90 candidates, totalling 450 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:777: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n  warn(\n"},{"name":"stdout","output_type":"stream","text":"['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 90 candidates, totalling 450 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:777: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n  warn(\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"}]},{"cell_type":"code","metadata":{"cell_id":"34440a238936476dbe0263ad72006e4b","deepnote_cell_type":"code"},"source":"dict_rf={}\n\nfor param_rf in param_rfs:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n################# revise\n                with open (path+'/clf_rf_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'rb') as f:\n                    [clf, df_cvresult, y_pred, y_pred_prob, clf_report]=pickle.load(f)\n################# revise\n                    dict_rf['clf_rf_{}_{}_{}_t{}_spl{}_km'.format(y_type, dtype, cv, test_year, n_splits)]=[clf, df_cvresult, y_pred, y_pred_prob, clf_report]\n                    \nfor idx, model in enumerate(dict_rf):\n    if idx==0:\n        df_rf=dict_rf[model][1]\n    else:\n        df_tmp=dict_rf[model][1]\n        df_rf=pd.concat([df_rf, df_tmp])\n                    \ndf_rf[df_rf.rank_test_recall==1]    ","execution_count":11,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_weight</th>\n      <th>max_features</th>\n      <th>n_estimators</th>\n      <th>warm_start</th>\n      <th>model</th>\n      <th>data</th>\n      <th>y</th>\n      <th>cv</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>rank_test_recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>balanced</td>\n      <td>0.2</td>\n      <td>30</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.622505</td>\n      <td>0.160321</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>balanced</td>\n      <td>0.2</td>\n      <td>30</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.622505</td>\n      <td>0.160321</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>balanced</td>\n      <td>0.3</td>\n      <td>30</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.622505</td>\n      <td>0.160321</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>balanced</td>\n      <td>0.3</td>\n      <td>30</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.622505</td>\n      <td>0.160321</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>None</td>\n      <td>0.7</td>\n      <td>50</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>ntr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.492086</td>\n      <td>0.144917</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>None</td>\n      <td>0.7</td>\n      <td>50</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>ntr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.492086</td>\n      <td>0.144917</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>balanced_subsample</td>\n      <td>0.2</td>\n      <td>50</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.667786</td>\n      <td>0.057932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>balanced_subsample</td>\n      <td>0.2</td>\n      <td>50</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.667786</td>\n      <td>0.057932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>balanced_subsample</td>\n      <td>0.3</td>\n      <td>50</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.667786</td>\n      <td>0.057932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>balanced_subsample</td>\n      <td>0.3</td>\n      <td>50</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.667786</td>\n      <td>0.057932</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>balanced_subsample</td>\n      <td>0.9</td>\n      <td>50</td>\n      <td>True</td>\n      <td>RF</td>\n      <td>ntr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.600483</td>\n      <td>0.123415</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>balanced_subsample</td>\n      <td>0.9</td>\n      <td>50</td>\n      <td>False</td>\n      <td>RF</td>\n      <td>ntr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.600483</td>\n      <td>0.123415</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          class_weight  max_features  n_estimators  warm_start model data  \\\n0             balanced           0.2            30        True    RF   tr   \n1             balanced           0.2            30       False    RF   tr   \n6             balanced           0.3            30        True    RF   tr   \n7             balanced           0.3            30       False    RF   tr   \n80                None           0.7            50        True    RF  ntr   \n81                None           0.7            50       False    RF  ntr   \n32  balanced_subsample           0.2            50        True    RF   tr   \n33  balanced_subsample           0.2            50       False    RF   tr   \n38  balanced_subsample           0.3            50        True    RF   tr   \n39  balanced_subsample           0.3            50       False    RF   tr   \n56  balanced_subsample           0.9            50        True    RF  ntr   \n57  balanced_subsample           0.9            50       False    RF  ntr   \n\n         y   cv  mean_test_recall  std_test_recall  rank_test_recall  \n0    y_agg  tss          0.622505         0.160321                 1  \n1    y_agg  tss          0.622505         0.160321                 1  \n6    y_agg  tss          0.622505         0.160321                 1  \n7    y_agg  tss          0.622505         0.160321                 1  \n80   y_agg  tss          0.492086         0.144917                 1  \n81   y_agg  tss          0.492086         0.144917                 1  \n32  y_oecd  tss          0.667786         0.057932                 1  \n33  y_oecd  tss          0.667786         0.057932                 1  \n38  y_oecd  tss          0.667786         0.057932                 1  \n39  y_oecd  tss          0.667786         0.057932                 1  \n56  y_oecd  tss          0.600483         0.123415                 1  \n57  y_oecd  tss          0.600483         0.123415                 1  "},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"scrolled":true,"cell_id":"41bad08d3cca49f1bd98f6a511e408cc","deepnote_cell_type":"code"},"source":"for idx, model in enumerate(dict_rf.keys()):\n    \n    report=dict_rf[model][-1]\n    \n    if idx==0:\n        df_rf_creport=classification_report_csv(report)\n        df_rf_creport['model']=model\n    else:\n        df_tmp=classification_report_csv(report)\n        df_tmp['model']=model\n        df_rf_creport=pd.concat([df_rf_creport, df_tmp])\n        \n\ndf_rf_creport","execution_count":12,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>support</th>\n      <th>accuracy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.96</td>\n      <td>0.86</td>\n      <td>0.91</td>\n      <td>56.0</td>\n      <td>0.83</td>\n      <td>clf_rf_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.83</td>\n      <td>clf_rf_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>0.83</td>\n      <td>clf_rf_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>56.0</td>\n      <td>0.93</td>\n      <td>clf_rf_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.93</td>\n      <td>clf_rf_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.93</td>\n      <td>clf_rf_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.96</td>\n      <td>0.84</td>\n      <td>0.90</td>\n      <td>56.0</td>\n      <td>0.82</td>\n      <td>clf_rf_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.18</td>\n      <td>0.50</td>\n      <td>0.27</td>\n      <td>4.0</td>\n      <td>0.82</td>\n      <td>clf_rf_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>56.0</td>\n      <td>0.93</td>\n      <td>clf_rf_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4.0</td>\n      <td>0.93</td>\n      <td>clf_rf_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   class  precision  recall  f1_score  support  accuracy  \\\n0    0.0       0.96    0.86      0.91     56.0      0.83   \n1    1.0       0.00    0.00      0.00      2.0      0.83   \n2    2.0       1.00    1.00      1.00      2.0      0.83   \n0    0.0       0.93    1.00      0.97     56.0      0.93   \n1    1.0       0.00    0.00      0.00      2.0      0.93   \n2    2.0       0.00    0.00      0.00      2.0      0.93   \n0    0.0       0.96    0.84      0.90     56.0      0.82   \n1    1.0       0.18    0.50      0.27      4.0      0.82   \n0    0.0       0.93    1.00      0.97     56.0      0.93   \n1    1.0       0.00    0.00      0.00      4.0      0.93   \n\n                              model  \n0    clf_rf_y_agg_tr_tss_t5_spl5_km  \n1    clf_rf_y_agg_tr_tss_t5_spl5_km  \n2    clf_rf_y_agg_tr_tss_t5_spl5_km  \n0   clf_rf_y_agg_ntr_tss_t5_spl5_km  \n1   clf_rf_y_agg_ntr_tss_t5_spl5_km  \n2   clf_rf_y_agg_ntr_tss_t5_spl5_km  \n0   clf_rf_y_oecd_tr_tss_t5_spl5_km  \n1   clf_rf_y_oecd_tr_tss_t5_spl5_km  \n0  clf_rf_y_oecd_ntr_tss_t5_spl5_km  \n1  clf_rf_y_oecd_ntr_tss_t5_spl5_km  "},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"7dc293e68dc543439d69b280f5f30b71","deepnote_cell_type":"code"},"source":"def svc_result(metadata, threshold, criteria, param_svc, y_type='y_agg' ,cv='tss', test_year=5, n_splits=5, dtype='tr'):\n    \n    if dtype=='tr':\n        X=pd.read_csv('../data/X_data_tr.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data_tr.csv', index_col='date', parse_dates=True)\n    else:\n        X=pd.read_csv('../data/X_data.csv', index_col='date', parse_dates=True)\n        y=pd.read_csv('../data/y_data.csv', index_col='date', parse_dates=True)\n\n################# revise\n    df_feature=select_features2(metadata, X, threshold, criteria=criteria)  #####################################\n    selected_features=list(df_feature[df_feature.select==1]['variable'])\n    \n    print(selected_features)\n\n    \n    ## train and validation set: X_train, y_train / final test set: X_test, y_test\n    X_train=X[selected_features][:-(test_year*12)]  \n    y_train=y[y_type][:-(test_year*12)]           \n    X_test=X[selected_features][-(test_year*12):]   \n    y_test=y[y_type][-(test_year*12):]\n    \n    ############################scaling#####################################\n    sc = StandardScaler()\n    X_scaled_train = sc.fit_transform(X_train)\n    X_scaled_test=sc.transform(X_test)\n    ############################scaling#####################################\n    \n    ## cross validation for parameter tuning & training\n    if cv=='block':\n        split=KFold(n_splits=n_splits, shuffle=False)  \n    else:\n        split=TimeSeriesSplit(n_splits=n_splits)\n    \n    \n    if y_type=='y_agg':\n        cw_dict={0:1,1:2,2:3}\n    else:\n        cw_dict={0:1,1:2}\n        \n    \n    clf = GridSearchCV(SVC(random_state=14, class_weight=cw_dict, probability=True), \n                       param_svc, cv=split, \n                       verbose=3, n_jobs=-1, scoring=['recall_macro'],\n                    refit='recall_macro'\n                    )\n\n    ############################scaling#####################################\n    clf.fit(X_scaled_train, y_train)\n    \n    ## training result\n    ############################scaling#####################################\n    y_pred_prob=clf.predict_proba(X_scaled_test)\n    y_pred = clf.predict(X_scaled_test)\n\n    clf_report=classification_report(y_test, y_pred)\n\n    param=clf.cv_results_['params']\n    mean_test_score=clf.cv_results_['mean_test_recall_macro']\n    std_test_score=clf.cv_results_['std_test_recall_macro']\n    rank_test_score=clf.cv_results_['rank_test_recall_macro']\n\n    for idx, x in enumerate(param):\n        x['model']='SVC'\n        x['data']=dtype\n        x['y']=y_type\n        x['cv']=cv\n        x['mean_test_recall']=mean_test_score[idx] \n        x['std_test_recall']=std_test_score[idx]         \n        x['rank_test_recall']=rank_test_score[idx]\n\n    df_cvresult=pd.DataFrame(param)\n################# revise\n    with open (path+'/clf_svc_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'wb') as f:\n        pickle.dump([clf, df_cvresult, y_pred, y_pred_prob, clf_report], f)\n","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"b2d01b7f792544349c8e2e78934a74ab","deepnote_cell_type":"code"},"source":"param_svcs=[{'C':[0.5, 1, 2, 5],\n             'kernel':['poly','rbf','sigmoid']}]  ## you can add more dictionary for other combinations of parameters.\ny_types=['y_agg','y_oecd']\ncvs=['tss']\ntest_year=5\nn_splits=5\ndtypes=['tr','ntr']\n\nfor param_svc in param_svcs:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n                svc_result(metadata, threshold, criteria, param_svc, y_type=y_type ,cv=cv, test_year=test_year, n_splits=n_splits, dtype=dtype)","execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"},{"name":"stdout","output_type":"stream","text":"['MANEMP', 'IPMANSICS', 'HOUST', 'T10YFFM']\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n['W875RX1', 'INDPRO', 'HOUST', 'WPSFD49207', 'CES0600000008', 'DSERRG3M086SBEA', 'REALLN', 'T10YFFM']\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n"},{"name":"stderr","output_type":"stream","text":"C:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\Users\\gredi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"}]},{"cell_type":"code","metadata":{"cell_id":"9b84b51ceb5748f4b9025d8ed7f03e46","deepnote_cell_type":"code"},"source":"dict_svc={}\n\nfor param_svc in param_svcs:\n    for y_type in y_types:\n        for cv in cvs:\n            for dtype in dtypes:\n################# revise\n                with open (path+'/clf_svc_{}_{}_{}_t{}_spl{}_km.pkl'.format(y_type, dtype, cv, test_year, n_splits), 'rb') as f:\n                    [clf, df_cvresult, y_pred, y_pred_prob, clf_report]=pickle.load(f)\n################# revise\n                    dict_svc['clf_svc_{}_{}_{}_t{}_spl{}_km'.format(y_type, dtype, cv, test_year, n_splits)]=[clf, df_cvresult, y_pred, y_pred_prob, clf_report]\n                    \nfor idx, model in enumerate(dict_svc):\n    if idx==0:\n        df_svc=dict_svc[model][1]\n    else:\n        df_tmp=dict_svc[model][1]\n        df_svc=pd.concat([df_svc, df_tmp])\n                    \ndf_svc[df_svc.rank_test_recall==1]    ","execution_count":15,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>kernel</th>\n      <th>model</th>\n      <th>data</th>\n      <th>y</th>\n      <th>cv</th>\n      <th>mean_test_recall</th>\n      <th>std_test_recall</th>\n      <th>rank_test_recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>2.0</td>\n      <td>rbf</td>\n      <td>SVC</td>\n      <td>tr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.593273</td>\n      <td>0.133577</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.0</td>\n      <td>rbf</td>\n      <td>SVC</td>\n      <td>ntr</td>\n      <td>y_agg</td>\n      <td>tss</td>\n      <td>0.435745</td>\n      <td>0.179567</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2.0</td>\n      <td>sigmoid</td>\n      <td>SVC</td>\n      <td>tr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.649191</td>\n      <td>0.107472</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>sigmoid</td>\n      <td>SVC</td>\n      <td>ntr</td>\n      <td>y_oecd</td>\n      <td>tss</td>\n      <td>0.612182</td>\n      <td>0.129262</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      C   kernel model data       y   cv  mean_test_recall  std_test_recall  \\\n7   2.0      rbf   SVC   tr   y_agg  tss          0.593273         0.133577   \n10  5.0      rbf   SVC  ntr   y_agg  tss          0.435745         0.179567   \n8   2.0  sigmoid   SVC   tr  y_oecd  tss          0.649191         0.107472   \n2   0.5  sigmoid   SVC  ntr  y_oecd  tss          0.612182         0.129262   \n\n    rank_test_recall  \n7                  1  \n10                 1  \n8                  1  \n2                  1  "},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"a8e307db6ce04c8caeaf8b5c25364802","deepnote_cell_type":"code"},"source":"for idx, model in enumerate(dict_svc.keys()):\n    \n    report=dict_svc[model][-1]\n    \n    if idx==0:\n        df_svc_creport=classification_report_csv(report)\n        df_svc_creport['model']=model\n    else:\n        df_tmp=classification_report_csv(report)\n        df_tmp['model']=model\n        df_svc_creport=pd.concat([df_svc_creport, df_tmp])\n        \n\ndf_svc_creport","execution_count":16,"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>support</th>\n      <th>accuracy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.94</td>\n      <td>0.54</td>\n      <td>0.68</td>\n      <td>56.0</td>\n      <td>0.53</td>\n      <td>clf_svc_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.04</td>\n      <td>0.50</td>\n      <td>0.07</td>\n      <td>2.0</td>\n      <td>0.53</td>\n      <td>clf_svc_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>2.0</td>\n      <td>0.53</td>\n      <td>clf_svc_y_agg_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.96</td>\n      <td>0.95</td>\n      <td>0.95</td>\n      <td>56.0</td>\n      <td>0.90</td>\n      <td>clf_svc_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.20</td>\n      <td>0.50</td>\n      <td>0.29</td>\n      <td>2.0</td>\n      <td>0.90</td>\n      <td>clf_svc_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>2.0</td>\n      <td>0.90</td>\n      <td>clf_svc_y_agg_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>0.50</td>\n      <td>0.65</td>\n      <td>56.0</td>\n      <td>0.50</td>\n      <td>clf_svc_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.07</td>\n      <td>0.50</td>\n      <td>0.12</td>\n      <td>4.0</td>\n      <td>0.50</td>\n      <td>clf_svc_y_oecd_tr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.93</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>56.0</td>\n      <td>0.93</td>\n      <td>clf_svc_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4.0</td>\n      <td>0.93</td>\n      <td>clf_svc_y_oecd_ntr_tss_t5_spl5_km</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   class  precision  recall  f1_score  support  accuracy  \\\n0    0.0       0.94    0.54      0.68     56.0      0.53   \n1    1.0       0.04    0.50      0.07      2.0      0.53   \n2    2.0       0.50    0.50      0.50      2.0      0.53   \n0    0.0       0.96    0.95      0.95     56.0      0.90   \n1    1.0       0.20    0.50      0.29      2.0      0.90   \n2    2.0       0.00    0.00      0.00      2.0      0.90   \n0    0.0       0.93    0.50      0.65     56.0      0.50   \n1    1.0       0.07    0.50      0.12      4.0      0.50   \n0    0.0       0.93    1.00      0.97     56.0      0.93   \n1    1.0       0.00    0.00      0.00      4.0      0.93   \n\n                               model  \n0    clf_svc_y_agg_tr_tss_t5_spl5_km  \n1    clf_svc_y_agg_tr_tss_t5_spl5_km  \n2    clf_svc_y_agg_tr_tss_t5_spl5_km  \n0   clf_svc_y_agg_ntr_tss_t5_spl5_km  \n1   clf_svc_y_agg_ntr_tss_t5_spl5_km  \n2   clf_svc_y_agg_ntr_tss_t5_spl5_km  \n0   clf_svc_y_oecd_tr_tss_t5_spl5_km  \n1   clf_svc_y_oecd_tr_tss_t5_spl5_km  \n0  clf_svc_y_oecd_ntr_tss_t5_spl5_km  \n1  clf_svc_y_oecd_ntr_tss_t5_spl5_km  "},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"cell_id":"59236bcbdf1e4d43b2fd823a316fe282","deepnote_cell_type":"code"},"source":"dict_list=[df_knn, df_knn_creport, df_rf, df_rf_creport, df_svc, df_svc_creport]\nid_list=['df_knn', 'df_knn_creport', 'df_rf', 'df_rf_creport', 'df_svc', 'df_svc_creport']\n\n# dict_list=[df_svc, df_svc_creport]\n# id_list=['df_svc', 'df_svc_creport']\n\n\n\nfor i, dict_ in enumerate(dict_list):\n################# revise\n    with open(path+'/{}_km.pkl'.format(id_list[i]), 'wb') as f:               \n        pickle.dump(dict_, f)","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"5a43d99e99f7407e8c2f2d1673526f0d","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"aa389cd8f69f409fbb72afcd3a58da5a","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dc2156ff-f31b-485a-9893-d89a520307c4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"toc":{"sideBar":true,"nav_menu":{},"toc_cell":false,"title_cell":"Table of Contents","toc_position":{},"skip_h1_title":false,"title_sidebar":"Contents","base_numbering":1,"number_sections":true,"toc_window_display":false,"toc_section_display":true},"deepnote":{},"hide_input":false,"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.9.12","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"cd367c1949544b6186d4ab31a92c1231","deepnote_execution_queue":[]}}